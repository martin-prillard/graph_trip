{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "978958f8",
   "metadata": {
    "id": "978958f8"
   },
   "source": [
    "# Malware Classification with Graph Embeddings\n",
    "\n",
    "This notebook builds an end-to-end workflow to detect malware from function-call graphs. We rely on the MalNet Tiny dataset distributed via PyTorch Geometric, transform the graphs into vector representations, explore their structure, and finally train both classical ML and GNN models for classification. The dataset is pulled automatically from the [PyTorch Geometric documentation](https://pytorch-geometric.readthedocs.io/en/2.4.0/generated/torch_geometric.datasets.MalNetTiny.html) so no manual downloads are required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IaIrgl-tu9St",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IaIrgl-tu9St",
    "outputId": "9e009821-1abc-4833-ac8e-9e93d9becdc3"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import torch\n",
    "from karateclub import Graph2Vec\n",
    "from umap.umap_ import UMAP\n",
    "import networkx as nx\n",
    "import plotly.express as px\n",
    "from torch_geometric.datasets import MalNetTiny\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "\n",
    "import pandas as pd\n",
    "from pycaret.classification import (\n",
    "    setup, compare_models, finalize_model,\n",
    "    tune_model, evaluate_model, save_model, load_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5450a3",
   "metadata": {
    "id": "0f5450a3"
   },
   "source": [
    "## 1. Load MalNet Tiny Graphs\n",
    "Use the `MalNetTiny` dataset helper to download the graphs automatically, and keep a balanced subset of 200 graphs per class for faster experimentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b8789",
   "metadata": {
    "id": "f92b8789"
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('data/malnet_tiny')\n",
    "DATA_SPLIT = 'train'\n",
    "CLASSES = ['addisplay', 'adware', 'benign', 'downloader', 'trojan']\n",
    "MAX_GRAPHS_PER_CLASS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ad598",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1742293730317,
     "user": {
      "displayName": "Inconnu Encore_plus",
      "userId": "05414670977465923281"
     },
     "user_tz": -60
    },
    "id": "5d4ad598",
    "outputId": "bcebc278-2cfa-4306-c44d-10841e87ed56"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# The MalNet Tiny graphs are downloaded automatically via torch_geometric.datasets.\n",
    "dataset = MalNetTiny(root=DATA_ROOT.as_posix(), split=DATA_SPLIT)\n",
    "per_class_counts = defaultdict(int)\n",
    "\n",
    "targets = []\n",
    "graphs = []\n",
    "\n",
    "for data in dataset:\n",
    "    class_idx = int(data.y)\n",
    "    class_name = CLASSES[class_idx]\n",
    "    if per_class_counts[class_name] >= MAX_GRAPHS_PER_CLASS:\n",
    "        continue\n",
    "\n",
    "    graph = to_networkx(data, to_undirected=True)\n",
    "    graph = nx.convert_node_labels_to_integers(graph, label_attribute='old_label')\n",
    "    graphs.append(graph)\n",
    "    targets.append(class_name)\n",
    "    per_class_counts[class_name] += 1\n",
    "\n",
    "    if len(per_class_counts) == len(CLASSES) and all(\n",
    "        count >= MAX_GRAPHS_PER_CLASS for count in per_class_counts.values()\n",
    "    ):\n",
    "        break\n",
    "\n",
    "summary = Counter(targets)\n",
    "f\"{len(graphs)} graphs loaded ({summary})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d840aa3-287a-46bc-ac28-2b825d8a414e",
   "metadata": {},
   "source": [
    "If you add and want to load the data locally:\n",
    "```python\n",
    "PATH_GRAPHS = 'malnet-graphs-tiny' # loocalfolder\n",
    "CLASSES = ['addisplay', 'adware', 'benign', 'downloader', 'trojan']\n",
    "MAX_GRAPHS_BY_CLASSE = 200\n",
    "\n",
    "targets = []\n",
    "graphs = []\n",
    "\n",
    "for classe in CLASSES:\n",
    "    files = Path(PATH_GRAPHS + '/' + classe).glob('*.edgelist')\n",
    "    for i, file in enumerate(files):\n",
    "        if i >= MAX_GRAPHS_BY_CLASSE:\n",
    "            break\n",
    "        targets.append(classe)\n",
    "        G = nx.read_edgelist(file)\n",
    "        G = nx.convert_node_labels_to_integers(G, label_attribute='old_label')\n",
    "        graphs.append(G)\n",
    "\n",
    "f\"{len(graphs)} graphes charg√©s ({dict(Counter(targets))})\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7dc9c",
   "metadata": {
    "id": "fda7dc9c"
   },
   "source": [
    "## 2. Graph Embedding\n",
    "Learn Graph2Vec representations that turn each graph into a dense vector suitable for downstream visualization and classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369dc814",
   "metadata": {
    "id": "369dc814"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "N_DIMENSIONS = 2\n",
    "\n",
    "graph2vec = Graph2Vec(dimensions=N_DIMENSIONS)\n",
    "graph2vec.fit(graphs)\n",
    "embeddings = graph2vec.get_embedding()\n",
    "print(embeddings.shape)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b2f68",
   "metadata": {
    "id": "db6b2f68"
   },
   "source": [
    "**Plot the embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hl9z4JL9lh3W",
   "metadata": {
    "id": "hl9z4JL9lh3W"
   },
   "source": [
    "The interactive scatterplot helps verify whether Graph2Vec separates the malware families.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e178619",
   "metadata": {
    "id": "9e178619"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(x=embeddings[:, 0], y=embeddings[:, 1], color=targets)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952eeb1",
   "metadata": {
    "id": "2952eeb1"
   },
   "source": [
    "## 3. Dimensionality Reduction\n",
    "Use UMAP to reduce the high-dimensional embeddings to 2D and 3D views that make cluster structures easier to inspect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ee5c8",
   "metadata": {
    "id": "685ee5c8"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "N_DIMENSIONS = 256\n",
    "\n",
    "graph2vec = Graph2Vec(dimensions=N_DIMENSIONS)\n",
    "graph2vec.fit(graphs)\n",
    "embeddings = graph2vec.get_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339dc33e",
   "metadata": {
    "id": "339dc33e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(embeddings)\n",
    "df['target'] = targets\n",
    "df.to_csv('malware_emb_500_256.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e992e7a",
   "metadata": {
    "id": "5e992e7a"
   },
   "source": [
    "**Project embeddings down to 2 dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30980523",
   "metadata": {
    "id": "30980523"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "proj_2d = UMAP(n_components=2, init='random', random_state=0).fit_transform(embeddings)\n",
    "proj_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae71c7",
   "metadata": {
    "id": "5dae71c7"
   },
   "source": [
    "**Plot the 2D embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2gTfpKI1XJ",
   "metadata": {
    "id": "cb2gTfpKI1XJ"
   },
   "outputs": [],
   "source": [
    "fig_2d = px.scatter(\n",
    "    proj_2d, x=0, y=1,\n",
    "    color=targets\n",
    ")\n",
    "fig_2d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7899b",
   "metadata": {
    "id": "b3b7899b"
   },
   "source": [
    "**Project embeddings down to 3 dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c21171",
   "metadata": {
    "id": "e0c21171"
   },
   "outputs": [],
   "source": [
    "proj_3d = UMAP(n_components=3, init='random', random_state=0).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b800e87",
   "metadata": {
    "id": "4b800e87"
   },
   "source": [
    "**Plot the 3D embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135dc66f",
   "metadata": {
    "id": "135dc66f"
   },
   "outputs": [],
   "source": [
    "fig_3d = px.scatter_3d(\n",
    "    proj_3d, x=0, y=1, z=2,\n",
    "    color=targets\n",
    ")\n",
    "fig_3d.update_traces(marker_size=5)\n",
    "fig_3d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55510dde",
   "metadata": {
    "id": "55510dde"
   },
   "source": [
    "## 4. Classical Classification\n",
    "Each graph is annotated with a malware family (or the benign label), so we can train a supervised classifier that predicts one of the five categories automatically. We rely on PyCaret to quickly compare algorithms, tune the best one, and persist the winning model for later inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d7f35e",
   "metadata": {
    "id": "80d7f35e"
   },
   "source": [
    "**Load the saved embeddings**\n",
    "\n",
    "Read the CSV file that stores the Graph2Vec representations alongside their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47583789",
   "metadata": {
    "id": "47583789"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('malware_emb_500_256.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f2e2c4",
   "metadata": {
    "id": "27f2e2c4"
   },
   "source": [
    "**Initialize PyCaret**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8536fe",
   "metadata": {
    "id": "ca8536fe"
   },
   "outputs": [],
   "source": [
    "setup(df, target=\"target\", fold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c576fac",
   "metadata": {
    "id": "2c576fac"
   },
   "source": [
    "**Compare models**\n",
    "PyCaret benchmarks a wide range of classifiers so we can pick the one that offers the best accuracy for the selected embedding dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be1a95",
   "metadata": {
    "id": "17be1a95"
   },
   "outputs": [],
   "source": [
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2d5be",
   "metadata": {
    "id": "dbe2d5be"
   },
   "source": [
    "**Tune the best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb658b",
   "metadata": {
    "id": "39eb658b"
   },
   "outputs": [],
   "source": [
    "best_model_tuned = tune_model(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5ee6ae",
   "metadata": {
    "id": "fb5ee6ae"
   },
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1a2a48",
   "metadata": {
    "id": "df1a2a48"
   },
   "outputs": [],
   "source": [
    "evaluate_model(best_model)\n",
    "# addisplay: 0, adware: 1, benign: 2, downloader: 3, trojan: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c1787",
   "metadata": {
    "id": "6e9c1787"
   },
   "source": [
    "**Save final model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1e336",
   "metadata": {
    "id": "a4a1e336"
   },
   "outputs": [],
   "source": [
    "final_model = finalize_model(best_model)\n",
    "save_model(final_model, 'ml_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81052e1e",
   "metadata": {
    "id": "81052e1e"
   },
   "outputs": [],
   "source": [
    "best_model = load_model('ml_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i68ofqznPJ3o",
   "metadata": {
    "id": "i68ofqznPJ3o"
   },
   "source": [
    "## 5. GNN-Based Classification\n",
    "Explore an end-to-end neural approach by training a Graph Convolutional Network (GCN) on the raw graphs instead of relying on precomputed embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JdOejP9kPjSZ",
   "metadata": {
    "id": "JdOejP9kPjSZ"
   },
   "source": [
    "**Convert NetworkX graphs into PyG Data objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fW71glC0t6Rz",
   "metadata": {
    "id": "fW71glC0t6Rz"
   },
   "outputs": [],
   "source": [
    "# Convert NetworkX graphs into PyG Data objects, adding placeholder node features and labels.\n",
    "def convert_to_pyg(graphs, targets):\n",
    "    data_list = []\n",
    "    for i, graph in enumerate(graphs):\n",
    "        for node in graph.nodes():\n",
    "            graph.nodes[node]['x'] = [1.0]  # Constant node feature placeholder\n",
    "\n",
    "        data = from_networkx(graph)\n",
    "        data.y = torch.tensor([targets[i]], dtype=torch.long)\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "class_mapping = {'addisplay': 0, 'adware': 1, 'benign': 2, 'downloader': 3, 'trojan': 4}\n",
    "encoded_targets = [class_mapping[label] for label in targets]\n",
    "\n",
    "data_list = convert_to_pyg(graphs, encoded_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qglUVAZUPa4J",
   "metadata": {
    "id": "qglUVAZUPa4J"
   },
   "source": [
    "**Create train/test splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z_2qLd2XulW_",
   "metadata": {
    "id": "Z_2qLd2XulW_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import BatchNorm, GCNConv, global_mean_pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the dataset into train and test partitions\n",
    "train_data, test_data = train_test_split(\n",
    "    data_list,\n",
    "    test_size=int(len(data_list) * 0.3),\n",
    "    stratify=encoded_targets,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Build PyG dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ShA__SbTP7Sz",
   "metadata": {
    "id": "ShA__SbTP7Sz"
   },
   "source": [
    "**Define the GNN architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CT5SVZ4L7LrE",
   "metadata": {
    "id": "CT5SVZ4L7LrE"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Dropout\n",
    "\n",
    "# Deeper GNN classifier with normalization and dropout regularization\n",
    "class ImprovedGNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.norms = torch.nn.ModuleList()\n",
    "\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        self.norms.append(BatchNorm(hidden_channels))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "            self.norms.append(BatchNorm(hidden_channels))\n",
    "\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.fc = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        for conv, norm in zip(self.convs, self.norms):\n",
    "            x = conv(x, edge_index)\n",
    "            x = norm(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.fc(x)\n",
    "\n",
    "in_channels = 1\n",
    "hidden_channels = 256  # Increased hidden size for better capacity\n",
    "out_channels = len(class_mapping)\n",
    "num_layers = 8  # Stack more GCN layers\n",
    "dropout = 0.5\n",
    "\n",
    "model = ImprovedGNNClassifier(in_channels, hidden_channels, out_channels, num_layers, dropout)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / max(1, len(train_loader))\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    preds, labels = [], []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch)\n",
    "        predictions = out.argmax(dim=1)\n",
    "        correct += (predictions == batch.y).sum().item()\n",
    "        preds.extend(predictions.cpu().tolist())\n",
    "        labels.extend(batch.y.cpu().tolist())\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    return accuracy, preds, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Amy-HAmbhd1T",
   "metadata": {
    "id": "Amy-HAmbhd1T"
   },
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df8Bl47ZHe",
   "metadata": {
    "id": "32df8Bl47ZHe"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train()\n",
    "    train_acc, _, _ = test(train_loader)\n",
    "    test_acc, _, _ = test(test_loader)\n",
    "    print(f\"Epoch {epoch:02d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "    # Step the scheduler based on the latest loss\n",
    "    scheduler.step(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DbH_7JjsQLC9",
   "metadata": {
    "id": "DbH_7JjsQLC9"
   },
   "outputs": [],
   "source": [
    "# Rapport final\n",
    "_, all_preds, all_labels = test(test_loader)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=list(class_mapping.keys())))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
